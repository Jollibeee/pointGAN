{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook will help you train a raw Point-Cloud GAN.\n",
    "\n",
    "(Assumes\n",
    "latent_3d_points is in the PYTHONPATH and that a trained AE model exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "2"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /home/sohee/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os.path as osp\n",
    "import matplotlib.pylab as plt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "BASE = os.path.dirname(os.path.abspath(os.path.dirname(\"file\"))) # latent_3D\n",
    "sys.path.append(BASE) \n",
    "\n",
    "from src.autoencoder import Configuration as Conf\n",
    "from src.neural_net import MODEL_SAVER_ID\n",
    "\n",
    "from src.in_out import snc_category_to_synth_id, create_dir, PointCloudDataSet, \\\n",
    "                                        load_all_point_clouds_under_folder\n",
    "\n",
    "from src.general_utils import plot_3d_point_cloud\n",
    "from src.tf_utils import reset_tf_graph\n",
    "\n",
    "from src.vanilla_gan import Vanilla_GAN\n",
    "from src.w_gan_gp import W_GAN_GP\n",
    "from src.generators_discriminators import point_cloud_generator,\\\n",
    "mlp_discriminator, leaky_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "3"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "4"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class_name = 'chair'\n",
    "# Use to save Neural-Net check-points etc.\n",
    "top_out_dir = 'log/pointnet'          \n",
    "\n",
    "# Top-dir of where point-clouds are stored.\n",
    "top_in_dir = 'data/shape_net_core_uniform_samples_2048/'\n",
    "\n",
    "top_out_dir = osp.join(BASE, top_out_dir, class_name)\n",
    "top_in_dir = osp.join(BASE, top_in_dir)\n",
    "\n",
    "experiment_name = 'raw_gan_with_w_gan_loss'\n",
    "\n",
    "n_pc_points = 2048                # Number of points per model.\n",
    "# class_name = raw_input('Give me the class name (e.g. \"chair\"): ').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "5"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "6778 pclouds were loaded. They belong in 1 shape-classes.\n",
      "Shape of DATA = (6778, 2048, 3)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Load point-clouds.\n",
    "syn_id = snc_category_to_synth_id()[class_name]\n",
    "class_dir = osp.join(top_in_dir , syn_id)\n",
    "all_pc_data = load_all_point_clouds_under_folder(class_dir, n_threads=8, file_ending='.ply', verbose=True)\n",
    "print ('Shape of DATA =', all_pc_data.point_clouds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set GAN parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "14"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "use_wgan = True     # Wasserstein with gradient penalty, or not?\n",
    "n_epochs = 10       # Epochs to train.\n",
    "\n",
    "plot_train_curve = True\n",
    "save_gan_model = True\n",
    "saver_step = np.hstack([np.array([1, 5, 10]), np.arange(50, n_epochs + 1, 50)])\n",
    "\n",
    "# If true, every 'saver_step' epochs we produce & save synthetic pointclouds.\n",
    "save_synthetic_samples = True\n",
    "# How many synthetic samples to produce at each save step.\n",
    "n_syn_samples = all_pc_data.num_examples\n",
    "\n",
    "# Optimization parameters\n",
    "init_lr = 0.0001\n",
    "batch_size = 50\n",
    "noise_params = {'mu':0, 'sigma': 0.2}\n",
    "noise_dim = 128\n",
    "beta = 0.5 # ADAM's momentum.\n",
    "\n",
    "n_out = [n_pc_points, 3] # Dimensionality of generated samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "discriminator = mlp_discriminator\n",
    "generator = point_cloud_generator\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "if save_synthetic_samples:\n",
    "    synthetic_data_out_dir = osp.join(top_out_dir, 'OUT/synthetic_samples/', experiment_name)\n",
    "    create_dir(synthetic_data_out_dir)\n",
    "\n",
    "if save_gan_model:\n",
    "    train_dir = osp.join(top_out_dir, 'OUT/raw_gan', experiment_name)\n",
    "    create_dir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "15"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "dis <function mlp_discriminator at 0x7fa24af79b70>\n",
      "gen <function point_cloud_generator at 0x7fa24af900d0>\n",
      "gen out = gen(noise)\n",
      "gen decoder\n",
      "decoder_fc_0 Tensor(\"raw_gan_with_w_gan_loss_1/generator/decoder_fc_0/BiasAdd:0\", shape=(?, 64), dtype=float32)\n",
      "decoder_fc_1 Tensor(\"raw_gan_with_w_gan_loss_1/generator/decoder_fc_1/BiasAdd:0\", shape=(?, 128), dtype=float32)\n",
      "decoder_fc_2 Tensor(\"raw_gan_with_w_gan_loss_1/generator/decoder_fc_2/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "decoder_fc_3 Tensor(\"raw_gan_with_w_gan_loss_1/generator/decoder_fc_3/BiasAdd:0\", shape=(?, 1024), dtype=float32)\n",
      "gen_dec  Tensor(\"raw_gan_with_w_gan_loss_1/generator/FullyConnected/BiasAdd:0\", shape=(?, 6144), dtype=float32)\n",
      "gen_dec  Tensor(\"raw_gan_with_w_gan_loss_1/generator/Reshape:0\", shape=(?, 2048, 3), dtype=float32)\n",
      "dis(real)\n",
      "dis encoder\n",
      "encoder_conv_layer_0 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator/raw_gan_with_w_gan_loss/discriminator/encoder_conv_layer_0/Squeeze:0\", shape=(?, 2048, 64), dtype=float32)\n",
      "encoder_conv_layer_0 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator/Relu:0\", shape=(?, 2048, 64), dtype=float32)\n",
      "encoder_conv_layer_1 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator/raw_gan_with_w_gan_loss/discriminator/encoder_conv_layer_1/Squeeze:0\", shape=(?, 2048, 128), dtype=float32)\n",
      "encoder_conv_layer_1 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator/Relu_1:0\", shape=(?, 2048, 128), dtype=float32)\n",
      "encoder_conv_layer_2 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator/raw_gan_with_w_gan_loss/discriminator/encoder_conv_layer_2/Squeeze:0\", shape=(?, 2048, 256), dtype=float32)\n",
      "encoder_conv_layer_2 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator/Relu_2:0\", shape=(?, 2048, 256), dtype=float32)\n",
      "encoder_conv_layer_3 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator/raw_gan_with_w_gan_loss/discriminator/encoder_conv_layer_3/Squeeze:0\", shape=(?, 2048, 256), dtype=float32)\n",
      "encoder_conv_layer_3 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator/Relu_3:0\", shape=(?, 2048, 256), dtype=float32)\n",
      "encoder_conv_layer_4 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator/raw_gan_with_w_gan_loss/discriminator/encoder_conv_layer_4/Squeeze:0\", shape=(?, 2048, 512), dtype=float32)\n",
      "encoder_conv_layer_4 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator/Relu_4:0\", shape=(?, 2048, 512), dtype=float32)\n",
      "dis decoder\n",
      "decoder_fc_0 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator/raw_gan_with_w_gan_loss/discriminator/decoding_logits/decoder_fc_0/BiasAdd:0\", shape=(?, 128), dtype=float32)\n",
      "decoder_fc_1 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator/raw_gan_with_w_gan_loss/discriminator/decoding_logits/decoder_fc_1/BiasAdd:0\", shape=(?, 64), dtype=float32)\n",
      "decoder_fc_2 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator/raw_gan_with_w_gan_loss/discriminator/decoding_logits/decoder_fc_2/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "dis(gen_out)\n",
      "dis encoder\n",
      "encoder_conv_layer_0 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator/raw_gan_with_w_gan_loss/discriminator/encoder_conv_layer_0_1/Squeeze:0\", shape=(?, 2048, 64), dtype=float32)\n",
      "encoder_conv_layer_0 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator/Relu_7:0\", shape=(?, 2048, 64), dtype=float32)\n",
      "encoder_conv_layer_1 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator/raw_gan_with_w_gan_loss/discriminator/encoder_conv_layer_1_1/Squeeze:0\", shape=(?, 2048, 128), dtype=float32)\n",
      "encoder_conv_layer_1 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator/Relu_8:0\", shape=(?, 2048, 128), dtype=float32)\n",
      "encoder_conv_layer_2 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator/raw_gan_with_w_gan_loss/discriminator/encoder_conv_layer_2_1/Squeeze:0\", shape=(?, 2048, 256), dtype=float32)\n",
      "encoder_conv_layer_2 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator/Relu_9:0\", shape=(?, 2048, 256), dtype=float32)\n",
      "encoder_conv_layer_3 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator/raw_gan_with_w_gan_loss/discriminator/encoder_conv_layer_3_1/Squeeze:0\", shape=(?, 2048, 256), dtype=float32)\n",
      "encoder_conv_layer_3 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator/Relu_10:0\", shape=(?, 2048, 256), dtype=float32)\n",
      "encoder_conv_layer_4 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator/raw_gan_with_w_gan_loss/discriminator/encoder_conv_layer_4_1/Squeeze:0\", shape=(?, 2048, 512), dtype=float32)\n",
      "encoder_conv_layer_4 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator/Relu_11:0\", shape=(?, 2048, 512), dtype=float32)\n",
      "dis decoder\n",
      "decoder_fc_0 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator/raw_gan_with_w_gan_loss/discriminator/decoding_logits/decoder_fc_0_1/BiasAdd:0\", shape=(?, 128), dtype=float32)\n",
      "decoder_fc_1 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator/raw_gan_with_w_gan_loss/discriminator/decoding_logits/decoder_fc_1_1/BiasAdd:0\", shape=(?, 64), dtype=float32)\n",
      "decoder_fc_2 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator/raw_gan_with_w_gan_loss/discriminator/decoding_logits/decoder_fc_2_1/BiasAdd:0\", shape=(?, 1), dtype=float32)\n",
      "dis encoder\n",
      "encoder_conv_layer_0 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator_1/raw_gan_with_w_gan_loss/discriminator/encoder_conv_layer_0/Squeeze:0\", shape=(?, 2048, 64), dtype=float32)\n",
      "encoder_conv_layer_0 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator_1/Relu:0\", shape=(?, 2048, 64), dtype=float32)\n",
      "encoder_conv_layer_1 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator_1/raw_gan_with_w_gan_loss/discriminator/encoder_conv_layer_1/Squeeze:0\", shape=(?, 2048, 128), dtype=float32)\n",
      "encoder_conv_layer_1 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator_1/Relu_1:0\", shape=(?, 2048, 128), dtype=float32)\n",
      "encoder_conv_layer_2 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator_1/raw_gan_with_w_gan_loss/discriminator/encoder_conv_layer_2/Squeeze:0\", shape=(?, 2048, 256), dtype=float32)\n",
      "encoder_conv_layer_2 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator_1/Relu_2:0\", shape=(?, 2048, 256), dtype=float32)\n",
      "encoder_conv_layer_3 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator_1/raw_gan_with_w_gan_loss/discriminator/encoder_conv_layer_3/Squeeze:0\", shape=(?, 2048, 256), dtype=float32)\n",
      "encoder_conv_layer_3 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator_1/Relu_3:0\", shape=(?, 2048, 256), dtype=float32)\n",
      "encoder_conv_layer_4 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator_1/raw_gan_with_w_gan_loss/discriminator/encoder_conv_layer_4/Squeeze:0\", shape=(?, 2048, 512), dtype=float32)\n",
      "encoder_conv_layer_4 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator_1/Relu_4:0\", shape=(?, 2048, 512), dtype=float32)\n",
      "dis decoder\n",
      "decoder_fc_0 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator_1/raw_gan_with_w_gan_loss/discriminator/decoding_logits/decoder_fc_0/BiasAdd:0\", shape=(?, 128), dtype=float32)\n",
      "decoder_fc_1 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator_1/raw_gan_with_w_gan_loss/discriminator/decoding_logits/decoder_fc_1/BiasAdd:0\", shape=(?, 64), dtype=float32)\n",
      "decoder_fc_2 Tensor(\"raw_gan_with_w_gan_loss_1/discriminator_1/raw_gan_with_w_gan_loss/discriminator/decoding_logits/decoder_fc_2/BiasAdd:0\", shape=(?, 1), dtype=float32)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "reset_tf_graph()\n",
    "\n",
    "if use_wgan:\n",
    "    lam = 10\n",
    "    disc_kwargs = {'b_norm': False}\n",
    "    gan = W_GAN_GP(experiment_name, init_lr, lam, n_out, noise_dim,\n",
    "                    discriminator, generator,\n",
    "                    disc_kwargs=disc_kwargs, beta=beta)\n",
    "    \n",
    "else:    \n",
    "    leak = 0.2\n",
    "    disc_kwargs = {'non_linearity': leaky_relu(leak), 'b_norm': False}\n",
    "    gan = Vanilla_GAN(experiment_name, init_lr, n_out, noise_dim,\n",
    "                      discriminator, generator, beta=beta, disc_kwargs=disc_kwargs)\n",
    "\n",
    "accum_syn_data = []\n",
    "train_stats = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "{'graph': <tensorflow.python.framework.ops.Graph object at 0x7f8a3cb04198>, 'name': 'raw_gan_with_w_gan_loss', 'epoch': <tf.Variable 'raw_gan_with_w_gan_loss/epoch:0' shape=() dtype=float32_ref>, 'increment_epoch': <tf.Tensor 'raw_gan_with_w_gan_loss/AssignAdd:0' shape=() dtype=float32_ref>, 'no_op': <tf.Operation 'NoOp' type=NoOp>, 'noise_dim': 128, 'n_output': [2048, 3], 'discriminator': <function mlp_discriminator at 0x7f89a0792b70>, 'generator': <function point_cloud_generator at 0x7f89a07a90d0>, 'noise': <tf.Tensor 'raw_gan_with_w_gan_loss_1/Placeholder:0' shape=(?, 128) dtype=float32>, 'real_pc': <tf.Tensor 'raw_gan_with_w_gan_loss_1/Placeholder_1:0' shape=(?, 2048, 3) dtype=float32>, 'generator_out': <tf.Tensor 'raw_gan_with_w_gan_loss_1/generator/Reshape:0' shape=(?, 2048, 3) dtype=float32>, 'real_prob': <tf.Tensor 'raw_gan_with_w_gan_loss_1/discriminator/Sigmoid:0' shape=(?, 1) dtype=float32>, 'real_logit': <tf.Tensor 'raw_gan_with_w_gan_loss_1/discriminator/raw_gan_with_w_gan_loss/discriminator/decoding_logits/decoder_fc_2/BiasAdd:0' shape=(?, 1) dtype=float32>, 'synthetic_prob': <tf.Tensor 'raw_gan_with_w_gan_loss_1/discriminator/Sigmoid_1:0' shape=(?, 1) dtype=float32>, 'synthetic_logit': <tf.Tensor 'raw_gan_with_w_gan_loss_1/discriminator/raw_gan_with_w_gan_loss/discriminator/decoding_logits/decoder_fc_2_1/BiasAdd:0' shape=(?, 1) dtype=float32>, 'loss_d': <tf.Tensor 'raw_gan_with_w_gan_loss_1/add_1:0' shape=() dtype=float32>, 'loss_g': <tf.Tensor 'raw_gan_with_w_gan_loss_1/Neg:0' shape=() dtype=float32>, 'opt_d': <tf.Operation 'raw_gan_with_w_gan_loss_1/Adam' type=NoOp>, 'opt_g': <tf.Operation 'raw_gan_with_w_gan_loss_1/Adam_1' type=NoOp>, 'saver': <tensorflow.python.training.saver.Saver object at 0x7f899031ee10>, 'init': <tf.Operation 'raw_gan_with_w_gan_loss_1/init' type=NoOp>, 'sess': <tensorflow.python.client.session.Session object at 0x7f8983dee390>}\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(gan.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Train the GAN.\n",
    "for _ in range(n_epochs):\n",
    "    loss, duration = gan._single_epoch_train(all_pc_data, batch_size, noise_params)\n",
    "    epoch = int(gan.sess.run(gan.increment_epoch))\n",
    "    print (epoch, loss)\n",
    "\n",
    "    if save_gan_model and epoch in saver_step:\n",
    "        checkpoint_path = osp.join(train_dir, MODEL_SAVER_ID)\n",
    "        gan.saver.save(gan.sess, checkpoint_path, global_step=gan.epoch)\n",
    "\n",
    "    if save_synthetic_samples and epoch in saver_step:\n",
    "        syn_data = gan.generate(n_syn_samples, noise_params)\n",
    "        np.savez(osp.join(synthetic_data_out_dir, 'epoch_' + str(epoch)), syn_data)\n",
    "        for k in range(3):  # plot three (synthetic) random examples.\n",
    "            plot_3d_point_cloud(syn_data[k][:, 0], syn_data[k][:, 1], syn_data[k][:, 2],\n",
    "                               in_u_sphere=True)\n",
    "\n",
    "    train_stats.append((epoch, ) + loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "27"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if plot_train_curve:\n",
    "    x = range(len(train_stats))\n",
    "    d_loss = [t[1] for t in train_stats]\n",
    "    g_loss = [t[2] for t in train_stats]\n",
    "    plt.plot(x, d_loss, '--')\n",
    "    plt.plot(x, g_loss)\n",
    "    plt.title('GAN training. (%s)' %(class_name))\n",
    "    plt.legend(['Discriminator', 'Generator'], loc=0)\n",
    "    \n",
    "    plt.tick_params(axis='x', which='both', bottom='off', top='off')\n",
    "    plt.tick_params(axis='y', which='both', left='off', right='off')\n",
    "    \n",
    "    plt.xlabel('Epochs.') \n",
    "    plt.ylabel('Loss.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}