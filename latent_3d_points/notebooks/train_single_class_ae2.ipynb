{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook will help you train a vanilla Point-Cloud AE with the basic architecture we used in our paper.\n",
    "    (it assumes latent_3d_points is in the PYTHONPATH and the structural losses have been compiled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sohee/coding/PointCloud/lgan/latent_3d_points\n",
      "WARNING:tensorflow:From /home/sohee/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "\n",
    "BASE = os.path.dirname(os.path.abspath(os.path.dirname(\"file\"))) # latent_3D\n",
    "sys.path.append(BASE)  # latent_3D\n",
    "print(BASE)\n",
    "\n",
    "from src.ae_templates import mlp_architecture_ala_iclr_18, default_train_params\n",
    "from src.autoencoder import Configuration as Conf\n",
    "from src.point_net_ae import PointNetAutoEncoder\n",
    "\n",
    "from src.in_out import snc_category_to_synth_id, create_dir, PointCloudDataSet, \\\n",
    "                                        load_all_point_clouds_under_folder\n",
    "\n",
    "from src.tf_utils import reset_tf_graph\n",
    "from src.general_utils import plot_3d_point_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -*- coding: utf-8 -*-\n",
    "# import numpy as np\n",
    "# import os\n",
    "# import os.path as osp\n",
    "# import sys\n",
    "# import matplotlib.pylab as plt\n",
    "\n",
    "# BASE = os.path.dirname(os.path.abspath(os.path.dirname(\"file\"))) # latent_3D\n",
    "# sys.path.append(BASE) \n",
    "\n",
    "# from src.point_net_ae import PointNetAutoEncoder\n",
    "# from src.autoencoder import Configuration as Conf\n",
    "# from src.neural_net import MODEL_SAVER_ID\n",
    "\n",
    "# from src.in_out import snc_category_to_synth_id, create_dir, PointCloudDataSet, \\\n",
    "#                                         load_all_point_clouds_under_folder\n",
    "\n",
    "# from src.general_utils import plot_3d_point_cloud\n",
    "# from src.tf_utils import reset_tf_graph\n",
    "\n",
    "# from src.vanilla_gan import Vanilla_GAN\n",
    "# from src.w_gan_gp import W_GAN_GP\n",
    "# from src.generators_discriminators import latent_code_discriminator_two_layers,\\\n",
    "# latent_code_generator_two_layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Basic Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = 'airplane'\n",
    "ae_loss = 'chamfer'                   # Loss to optimize: 'emd' or 'chamfer'\n",
    "\n",
    "top_out_dir = 'data/'          # Use to save Neural-Net check-points etc.\n",
    "top_in_dir = 'data/shape_net_core_uniform_samples_2048/' # Top-dir of where point-clouds are stored.\n",
    "\n",
    "top_out_dir = osp.join(BASE, top_out_dir, class_name)\n",
    "top_in_dir = osp.join(BASE, top_in_dir)\n",
    "\n",
    "\n",
    "load_pre_trained_ae = False\n",
    "restore_epoch = 10\n",
    "\n",
    "experiment_name = 'single_class_ae_' + ae_loss \n",
    "n_pc_points = 2048                # Number of points per model.\n",
    "bneck_size = 128                  # Bottleneck-AE size\n",
    "\n",
    "#class_name = input('Give me the class name (e.g. \"chair\"): ').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_params = default_train_params()\n",
    "train_params = {'batch_size': 50, \n",
    "                'training_epochs': 10,\n",
    "                'denoising': False,\n",
    "                'learning_rate': 0.0005,\n",
    "                'z_rotate': False,\n",
    "                'saver_step': 10,\n",
    "                'loss_display_step': 1\n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Point-Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4045 pclouds were loaded. They belong in 1 shape-classes.\n"
     ]
    }
   ],
   "source": [
    "syn_id = snc_category_to_synth_id()[class_name]\n",
    "class_dir = osp.join(top_in_dir , syn_id)\n",
    "all_pc_data = load_all_point_clouds_under_folder(class_dir, n_threads=8, file_ending='.ply', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load default training parameters (some of which are listed beloq). For more details please print the configuration object.\n",
    "\n",
    "    'batch_size': 50   \n",
    "    \n",
    "    'denoising': False     (# by default AE is not denoising)\n",
    "\n",
    "    'learning_rate': 0.0005\n",
    "\n",
    "    'z_rotate': False      (# randomly rotate models of each batch)\n",
    "    \n",
    "    'loss_display_step': 1 (# display loss at end of these many epochs)\n",
    "    'saver_step': 10       (# over how many epochs to save neural-network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, decoder, enc_args, dec_args = mlp_architecture_ala_iclr_18(n_pc_points, bneck_size)\n",
    "train_dir = create_dir(osp.join(top_out_dir, experiment_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = Conf(n_input = [n_pc_points, 3],\n",
    "            loss = ae_loss,\n",
    "            training_epochs = train_params['training_epochs'],\n",
    "            batch_size = train_params['batch_size'],\n",
    "            denoising = train_params['denoising'],\n",
    "            learning_rate = train_params['learning_rate'],\n",
    "            train_dir = train_dir,\n",
    "            loss_display_step = train_params['loss_display_step'],\n",
    "            saver_step = train_params['saver_step'],\n",
    "            z_rotate = train_params['z_rotate'],\n",
    "            encoder = encoder,\n",
    "            decoder = decoder,\n",
    "            encoder_args = enc_args,\n",
    "            decoder_args = dec_args\n",
    "           )\n",
    "conf.experiment_name = experiment_name\n",
    "conf.held_out_step = 5   # How often to evaluate/print out loss on \n",
    "                         # held_out data (if they are provided in ae.train() ).\n",
    "conf.save(osp.join(train_dir, 'configuration'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran the above lines, you can reload a saved model like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Encoder\n",
      "WARNING:tensorflow:From /home/sohee/anaconda3/envs/python3/lib/python3.6/site-packages/tflearn/initializations.py:119: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "encoder_conv_layer_0 conv params =  256\n",
      "bnorm params =  128\n",
      "Tensor(\"single_class_ae_chamfer_2/Relu:0\", shape=(?, 2048, 64), dtype=float32)\n",
      "output size: 131072 \n",
      "\n",
      "encoder_conv_layer_1 conv params =  8320\n",
      "bnorm params =  256\n",
      "Tensor(\"single_class_ae_chamfer_2/Relu_1:0\", shape=(?, 2048, 128), dtype=float32)\n",
      "output size: 262144 \n",
      "\n",
      "encoder_conv_layer_2 conv params =  16512\n",
      "bnorm params =  256\n",
      "Tensor(\"single_class_ae_chamfer_2/Relu_2:0\", shape=(?, 2048, 128), dtype=float32)\n",
      "output size: 262144 \n",
      "\n",
      "encoder_conv_layer_3 conv params =  33024\n",
      "bnorm params =  512\n",
      "Tensor(\"single_class_ae_chamfer_2/Relu_3:0\", shape=(?, 2048, 256), dtype=float32)\n",
      "output size: 524288 \n",
      "\n",
      "encoder_conv_layer_4 conv params =  32896\n",
      "bnorm params =  256\n",
      "Tensor(\"single_class_ae_chamfer_2/Relu_4:0\", shape=(?, 2048, 128), dtype=float32)\n",
      "output size: 262144 \n",
      "\n",
      "Tensor(\"single_class_ae_chamfer_2/Max:0\", shape=(?, 128), dtype=float32)\n",
      "Building Decoder\n",
      "decoder_fc_0 FC params =  33024\n",
      "Tensor(\"single_class_ae_chamfer_2/Relu_5:0\", shape=(?, 256), dtype=float32)\n",
      "output size: 256 \n",
      "\n",
      "decoder_fc_1 FC params =  65792\n",
      "Tensor(\"single_class_ae_chamfer_2/Relu_6:0\", shape=(?, 256), dtype=float32)\n",
      "output size: 256 \n",
      "\n",
      "decoder_fc_2 FC params =  1579008\n",
      "Tensor(\"single_class_ae_chamfer_2/decoder_fc_2/BiasAdd:0\", shape=(?, 6144), dtype=float32)\n",
      "output size: 6144 \n",
      "\n",
      "WARNING:tensorflow:From /home/sohee/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/sohee/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    }
   ],
   "source": [
    "if load_pre_trained_ae:\n",
    "    conf = Conf.load(train_dir + '/configuration')\n",
    "    reset_tf_graph()\n",
    "    ae = PointNetAutoEncoder(conf.experiment_name, conf)\n",
    "    ae.restore_model(conf.train_dir, epoch=restore_epoch)\n",
    "else :\n",
    "    reset_tf_graph()\n",
    "    ae = PointNetAutoEncoder(conf.experiment_name, conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build AE Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset_tf_graph()\n",
    "# ae = PointNetAutoEncoder(conf.experiment_name, conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the AE (save output to train_stats.txt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 \t training time =  0: 0: 5 \t loss = 0.004620010\n",
      "INFO:tensorflow:/home/sohee/coding/PointCloud/lgan/latent_3d_points/data/airplane/single_class_ae_chamfer/models.ckpt-1 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Epoch: 0002 \t training time =  0: 0: 3 \t loss = 0.000670234\n",
      "Epoch: 0003 \t training time =  0: 0: 3 \t loss = 0.000569327\n",
      "Epoch: 0004 \t training time =  0: 0: 3 \t loss = 0.000518557\n",
      "Epoch: 0005 \t training time =  0: 0: 3 \t loss = 0.000477906\n",
      "Epoch: 0006 \t training time =  0: 0: 3 \t loss = 0.000447839\n",
      "Epoch: 0007 \t training time =  0: 0: 3 \t loss = 0.000420319\n",
      "Epoch: 0008 \t training time =  0: 0: 3 \t loss = 0.000409983\n",
      "Epoch: 0009 \t training time =  0: 0: 3 \t loss = 0.000398358\n",
      "Epoch: 0010 \t training time =  0: 0: 3 \t loss = 0.000378030\n",
      "INFO:tensorflow:/home/sohee/coding/PointCloud/lgan/latent_3d_points/data/airplane/single_class_ae_chamfer/models.ckpt-10 is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "buf_size = 1 # Make 'training_stats' file to flush each output line regarding training.\n",
    "fout = open(osp.join(conf.train_dir, 'train_stats.txt'), 'a', buf_size)\n",
    "train_stats = ae.train(all_pc_data, conf, log_file=fout)\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sohee/coding/PointCloud/lgan/latent_3d_points/data/airplane/single_class_ae_chamfer\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_train_curve = True\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "print(conf.train_dir) # ../data/single_class_ae\n",
    "\n",
    "if plot_train_curve:\n",
    "    x = range(len(train_stats))\n",
    "    loss = [t[1] for t in train_stats] # [0] epoch  [1] loss  [2] time\n",
    "\n",
    "    plt.plot(x, loss)\n",
    "    plt.title('AE training. (%s)' %(class_name))\n",
    "    \n",
    "    plt.tick_params(axis='x', which='both', bottom=False, top=False)\n",
    "    plt.tick_params(axis='y', which='both', left=False, right=False)\n",
    "    \n",
    "    plt.xlabel('Epochs.') \n",
    "    plt.ylabel('Loss.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runtime :  0: 0:34 / 10 epoch\n"
     ]
    }
   ],
   "source": [
    "how_long_time = True\n",
    "\n",
    "\n",
    "if how_long_time:\n",
    "    time = [t[2] for t in train_stats] \n",
    "total = sum(time)  \n",
    "m, s = divmod(total, 60)\n",
    "h, m = divmod(m, 60)\n",
    "\n",
    "print('Total runtime : %2d:%2d:%2d / %d epoch' %(h, m, s, len(time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a batch of reconstuctions and their latent-codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 819\n",
    "feed_pc, feed_model_names, _ = all_pc_data.next_batch(num)\n",
    "reconstructions = ae.reconstruct(feed_pc)[0]\n",
    "latent_codes = ae.transform(feed_pc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use any plotting mechanism such as matplotlib to visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "plot_3d_point_cloud(reconstructions[i][:, 0], \n",
    "                    reconstructions[i][:, 1], \n",
    "                    reconstructions[i][:, 2], in_u_sphere=True);\n",
    "\n",
    "i = 4\n",
    "plot_3d_point_cloud(reconstructions[i][:, 0], \n",
    "                    reconstructions[i][:, 1], \n",
    "                    reconstructions[i][:, 2], in_u_sphere=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# f = open(osp.join(conf.train_dir, 'ae_reconstruction.txt'), 'a')\n",
    "# f.write(reconstructions)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os           \n",
    "import tensorflow as tf\n",
    "\n",
    "def createDir(dirname, path=os.getcwd()):\n",
    "    dirpath = osp.join(path, dirname)\n",
    "    try:\n",
    "        os.mkdir(dirpath)\n",
    "    except OSError as error:\n",
    "        print (\"exist\")\n",
    "        \n",
    "# os.makedirs(osp.join(conf.train_dir, 'ae_npy'))\n",
    "# os.makedirs(osp.join(conf.train_dir, 'ae_txt'))\n",
    "\n",
    "createDir('ae_npy', conf.train_dir)\n",
    "createDir('ae_txt', conf.train_dir)\n",
    "\n",
    "np.savez(osp.join(conf.train_dir, 'ae_npy', 'ae_reconstructions.npz'), reconstructions)\n",
    "np.save(osp.join(conf.train_dir, 'ae_npy', 'ae.npy'), reconstructions)\n",
    "      \n",
    "      \n",
    "for i in range(0,num):\n",
    "    xx = reconstructions[i][:, 0]\n",
    "    x = xx.tolist()\n",
    "    #     x = tf.convert_to_tensor(xx, dtype = tf.float32)\n",
    "    \n",
    "    yy = reconstructions[i][:, 1]\n",
    "    y = yy.tolist()\n",
    "    zz = reconstructions[i][:, 2]\n",
    "    z = zz.tolist()\n",
    "    \n",
    "    np.save(osp.join(conf.train_dir, 'ae_npy', 'ae_recon_'+ str(i).zfill(5) +'.npy'), reconstructions[i])\n",
    "    \n",
    "    \n",
    "      \n",
    "    p = open(osp.join(conf.train_dir, 'ae_txt', 'ae_recon_'+ str(i).zfill(5) +'.txt'), 'w+')\n",
    "    for k in range(0,2048):          \n",
    "        p.write('%8f\\t%8f\\t%8f\\n' %(x[k], y[k], z[k]))\n",
    "    p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
