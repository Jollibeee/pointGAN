{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook will help you train a vanilla Point-Cloud AE with the basic architecture we used in our paper.\n",
    "    (it assumes latent_3d_points is in the PYTHONPATH and the structural losses have been compiled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sohee/coding/PointCloud/lgan/latent_3d_points\n",
      "WARNING:tensorflow:From /home/sohee/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "\n",
    "BASE = os.path.dirname(os.path.abspath(os.path.dirname(\"file\"))) # latent_3D\n",
    "sys.path.append(BASE)  # latent_3D\n",
    "print(BASE)\n",
    "\n",
    "from src.ae_templates import mlp_architecture_ala_iclr_18, default_train_params, mlp_architecture_ldgcnn\n",
    "from src.autoencoder import Configuration as Conf\n",
    "from src.point_net_ae import PointNetAutoEncoder, LDGCNNAutoEncoder\n",
    "\n",
    "from src.in_out import snc_category_to_synth_id, create_dir, PointCloudDataSet, \\\n",
    "                                        load_all_point_clouds_under_folder\n",
    "\n",
    "from src.tf_utils import reset_tf_graph\n",
    "from src.general_utils import plot_3d_point_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -*- coding: utf-8 -*-\n",
    "# import numpy as np\n",
    "# import os\n",
    "# import os.path as osp\n",
    "# import sys\n",
    "# import matplotlib.pylab as plt\n",
    "\n",
    "# BASE = os.path.dirname(os.path.abspath(os.path.dirname(\"file\"))) # latent_3D\n",
    "# sys.path.append(BASE) \n",
    "\n",
    "# from src.point_net_ae import PointNetAutoEncoder\n",
    "# from src.autoencoder import Configuration as Conf\n",
    "# from src.neural_net import MODEL_SAVER_ID\n",
    "\n",
    "# from src.in_out import snc_category_to_synth_id, create_dir, PointCloudDataSet, \\\n",
    "#                                         load_all_point_clouds_under_folder\n",
    "\n",
    "# from src.general_utils import plot_3d_point_cloud\n",
    "# from src.tf_utils import reset_tf_graph\n",
    "\n",
    "# from src.vanilla_gan import Vanilla_GAN\n",
    "# from src.w_gan_gp import W_GAN_GP\n",
    "# from src.generators_discriminators import latent_code_discriminator_two_layers,\\\n",
    "# latent_code_generator_two_layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Basic Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = 'sofa'\n",
    "ae_loss = 'chamfer'                   # Loss to optimize: 'emd' or 'chamfer'\n",
    "\n",
    "top_out_dir = 'log/ldgcnn/'          # Use to save Neural-Net check-points etc.\n",
    "top_in_dir = 'data/shape_net_core_uniform_samples_2048/' # Top-dir of where point-clouds are stored.\n",
    "\n",
    "top_out_dir = osp.join(BASE, top_out_dir, class_name)\n",
    "top_in_dir = osp.join(BASE, top_in_dir)\n",
    "\n",
    "\n",
    "load_pre_trained_ae = False\n",
    "#True #False\n",
    "restore_epoch = 1000\n",
    "\n",
    "experiment_name = 'single_class_ae_' + ae_loss \n",
    "n_pc_points = 2048                # Number of points per model.\n",
    "bneck_size = 128                  # Bottleneck-AE size\n",
    "\n",
    "#class_name = input('Give me the class name (e.g. \"chair\"): ').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_params = default_train_params()\n",
    "train_params = {'batch_size': 50, \n",
    "                'training_epochs': 500,\n",
    "                'denoising': False,\n",
    "                'learning_rate': 0.0005,\n",
    "                'z_rotate': False,\n",
    "                'saver_step': 10,\n",
    "                'loss_display_step': 1\n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Point-Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3173 pclouds were loaded. They belong in 1 shape-classes.\n"
     ]
    }
   ],
   "source": [
    "syn_id = snc_category_to_synth_id()[class_name]\n",
    "class_dir = osp.join(top_in_dir , syn_id)\n",
    "all_pc_data = load_all_point_clouds_under_folder(class_dir, n_threads=8, file_ending='.ply', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load default training parameters (some of which are listed beloq). For more details please print the configuration object.\n",
    "\n",
    "    'batch_size': 50   \n",
    "    \n",
    "    'denoising': False     (# by default AE is not denoising)\n",
    "\n",
    "    'learning_rate': 0.0005\n",
    "\n",
    "    'z_rotate': False      (# randomly rotate models of each batch)\n",
    "    \n",
    "    'loss_display_step': 1 (# display loss at end of these many epochs)\n",
    "    'saver_step': 10       (# over how many epochs to save neural-network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder, decoder, enc_args, dec_args = mlp_architecture_ldgcnn(n_pc_points, bneck_size)\n",
    "train_dir = create_dir(osp.join(top_out_dir, experiment_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = Conf(n_input = [n_pc_points, 3],\n",
    "            loss = ae_loss,\n",
    "            training_epochs = train_params['training_epochs'],\n",
    "            batch_size = train_params['batch_size'],\n",
    "            denoising = train_params['denoising'],\n",
    "            learning_rate = train_params['learning_rate'],\n",
    "            train_dir = train_dir,\n",
    "            loss_display_step = train_params['loss_display_step'],\n",
    "            saver_step = train_params['saver_step'],\n",
    "            z_rotate = train_params['z_rotate'],\n",
    "            encoder = encoder,\n",
    "            decoder = decoder,\n",
    "            encoder_args = enc_args,\n",
    "            decoder_args = dec_args\n",
    "           )\n",
    "conf.experiment_name = experiment_name\n",
    "conf.held_out_step = 5   # How often to evaluate/print out loss on \n",
    "                         # held_out data (if they are provided in ae.train() ).\n",
    "conf.save(osp.join(train_dir, 'configuration'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran the above lines, you can reload a saved model like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of src.encoders_decoders failed: Traceback (most recent call last):\n",
      "  File \"/home/sohee/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/sohee/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 434, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/sohee/anaconda3/envs/python3/lib/python3.6/imp.py\", line 315, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/sohee/anaconda3/envs/python3/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 618, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 674, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 781, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 741, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/sohee/coding/PointCloud/lgan/latent_3d_points/src/encoders_decoders.py\", line 31\n",
      "    b_norm=True, non_linearity=tf.nn.relu, regularizer=None, weight_decay=0.001,\n",
      "    ^\n",
      "IndentationError: unexpected indent\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Encoder\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "filter length error: 1, only a length of 2 is supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-59f1630765c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mreset_tf_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLDGCNNAutoEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/coding/PointCloud/lgan/latent_3d_points/src/point_net_ae.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, configuration, graph)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbottleneck_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/coding/PointCloud/lgan/latent_3d_points/src/encoders_decoders.py\u001b[0m in \u001b[0;36mldgcnn_encoder\u001b[0;34m(in_signal, n_filters, filter_sizes, strides, b_norm, non_linearity, regularizer, weight_decay, symmetry, dropout_prob, pool, pool_sizes, scope, reuse, padding, verbose, closing, conv_op)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mscope_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpand_scope_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     layer = conv_op(edge_feature, nb_filter=64, filter_size=filter_sizes, strides=strides,\n\u001b[0;32m---> 55\u001b[0;31m                     regularizer=regularizer, weight_decay=weight_decay, name=name, reuse=reuse, scope=scope_i, padding=padding)\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tflearn/layers/conv.py\u001b[0m in \u001b[0;36mconv_2d\u001b[0;34m(incoming, nb_filter, filter_size, strides, padding, activation, bias, weights_init, bias_init, regularizer, weight_decay, trainable, restore, reuse, scope, name)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filter_size = utils.autoformat_filter_conv2d(filter_size,\n\u001b[1;32m     68\u001b[0m                                                  \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                                                  nb_filter)\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mstrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoformat_kernel_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoformat_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tflearn/utils.py\u001b[0m in \u001b[0;36mautoformat_filter_conv2d\u001b[0;34m(fsize, in_depth, out_depth)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             raise Exception(\"filter length error: \" + str(len(fsize))\n\u001b[0;32m--> 400\u001b[0;31m                             + \", only a length of 2 is supported.\")\n\u001b[0m\u001b[1;32m    401\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"filter format error: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: filter length error: 1, only a length of 2 is supported."
     ]
    }
   ],
   "source": [
    "if load_pre_trained_ae:\n",
    "    conf = Conf.load(train_dir + '/configuration')\n",
    "    reset_tf_graph()\n",
    "    ae = LDGCNNAutoEncoder(conf.experiment_name, conf)\n",
    "    ae.restore_model(conf.train_dir, epoch=restore_epoch)\n",
    "else :\n",
    "    reset_tf_graph()\n",
    "    ae = LDGCNNAutoEncoder(conf.experiment_name, conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build AE Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset_tf_graph()\n",
    "# ae = PointNetAutoEncoder(conf.experiment_name, conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the AE (save output to train_stats.txt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "buf_size = 1 # Make 'training_stats' file to flush each output line regarding training.\n",
    "fout = open(osp.join(conf.train_dir, 'train_stats.txt'), 'a', buf_size)\n",
    "train_stats = ae.train(all_pc_data, conf, log_file=fout)\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_curve = True\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "print(conf.train_dir) # ../data/single_class_ae\n",
    "\n",
    "if plot_train_curve:\n",
    "    x = range(len(train_stats))\n",
    "    loss = [t[1] for t in train_stats] # [0] epoch  [1] loss  [2] time\n",
    "\n",
    "    plt.plot(x, loss)\n",
    "    plt.title('AE training. (%s)' %(class_name))\n",
    "    \n",
    "    plt.tick_params(axis='x', which='both', bottom=False, top=False)\n",
    "    plt.tick_params(axis='y', which='both', left=False, right=False)\n",
    "    \n",
    "    plt.xlabel('Epochs.') \n",
    "    plt.ylabel('Loss.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "how_long_time = True\n",
    "\n",
    "\n",
    "if how_long_time:\n",
    "    time = [t[2] for t in train_stats] \n",
    "total = sum(time)  \n",
    "m, s = divmod(total, 60)\n",
    "h, m = divmod(m, 60)\n",
    "\n",
    "print('Total runtime : %2d:%2d:%2d / %d epoch' %(h, m, s, len(time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a batch of reconstuctions and their latent-codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num = all_pc_data.num_examples\n",
    "# print(num)\n",
    "\n",
    "# feed_pc, feed_model_names, _ = all_pc_data.next_batch(num)\n",
    "# reconstructions = ae.reconstruct(feed_pc)[0]\n",
    "# latent_codes = ae.transform(feed_pc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use any plotting mechanism such as matplotlib to visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 2\n",
    "# plot_3d_point_cloud(reconstructions[i][:, 0], \n",
    "#                     reconstructions[i][:, 1], \n",
    "#                     reconstructions[i][:, 2], in_u_sphere=True);\n",
    "\n",
    "# i = 4\n",
    "# plot_3d_point_cloud(reconstructions[i][:, 0], \n",
    "#                     reconstructions[i][:, 1], \n",
    "#                     reconstructions[i][:, 2], in_u_sphere=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import os           \n",
    "# import tensorflow as tf\n",
    "\n",
    "# def createDir(dirname, path=os.getcwd()):\n",
    "#     dirpath = osp.join(path, dirname)\n",
    "#     try:\n",
    "#         os.mkdir(dirpath)\n",
    "#     except OSError as error:\n",
    "#         print (\"exist\")\n",
    "        \n",
    "# # os.makedirs(osp.join(conf.train_dir, 'ae_npy'))\n",
    "# # os.makedirs(osp.join(conf.train_dir, 'ae_txt'))\n",
    "\n",
    "# createDir('ae_npy', conf.train_dir)\n",
    "# createDir('ae_txt', conf.train_dir)\n",
    "\n",
    "# # np.savez(osp.join(conf.train_dir, 'ae_npy', 'ae_reconstructions.npz'), reconstructions)\n",
    "# np.save(osp.join(conf.train_dir, 'ae_npy', 'ae.npy'), reconstructions)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# f = open(osp.join(conf.train_dir, 'ae_reconstruction.txt'), 'a')\n",
    "# f.write(reconstructions)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# for i in range(0,num):\n",
    "#     xx = reconstructions[i][:, 0]\n",
    "#     x = xx.tolist()\n",
    "#     #     x = tf.convert_to_tensor(xx, dtype = tf.float32)\n",
    "    \n",
    "#     yy = reconstructions[i][:, 1]\n",
    "#     y = yy.tolist()\n",
    "#     zz = reconstructions[i][:, 2]\n",
    "#     z = zz.tolist()\n",
    "    \n",
    "#     np.save(osp.join(conf.train_dir, 'ae_npy', 'ae_recon_'+ str(i).zfill(5) +'.npy'), reconstructions[i])\n",
    "    \n",
    "    \n",
    "      \n",
    "#     p = open(osp.join(conf.train_dir, 'ae_txt', 'ae_recon_'+ str(i).zfill(5) +'.txt'), 'w+')\n",
    "#     for k in range(0,2048):          \n",
    "#         p.write('%8f\\t%8f\\t%8f\\n' %(x[k], y[k], z[k]))\n",
    "#     p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
